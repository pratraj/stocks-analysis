{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36743c58-b00e-46ab-be10-97a61d4b69c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade firebase-admin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1544a0b-33c3-4a6e-905f-e52bdfbee2a9",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9e3ae0e-dd38-4b93-9faf-0aa3eceaeda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make a request to get the company tickers file\n",
    "import requests\n",
    "# To access local files\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# For DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "# For type hints\n",
    "from typing import List\n",
    "\n",
    "# For regular expression matching\n",
    "import re\n",
    "# Handle json tasks\n",
    "import json\n",
    "\n",
    "# For firebase access\n",
    "import firebase_admin\n",
    "from firebase_admin import credentials\n",
    "from firebase_admin import firestore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ebe142-bcfa-4dbf-8b39-43c1d6154f31",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81e7602e-47b8-4a5b-a59c-116efdbdcc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Path\n",
    "DATA_PATH = 'data'\n",
    "# Config path\n",
    "CONFIG_PATH = 'config'\n",
    "\n",
    "# Constant for Form 10-K\n",
    "FORM_10K = '10-K'\n",
    "# Constant for Form 10-Q\n",
    "FORM_10Q = '10-Q'\n",
    "# Forms in scope\n",
    "FORMS_SCOPE = [FORM_10K, FORM_10Q]\n",
    "\n",
    "# List of Submissions fields we are interersted\n",
    "SUB_DTYPES = {'adsh':str,'cik':'int32','name':str,'sic':str,'countryba':str,'fye':str,\n",
    "              'form':str,'period':str,'fy':'str','fp':str,'filed':str,'accepted':str}\n",
    "# Listy of Numbers fields we are interested\n",
    "NUM_DTYPES = {'adsh':str,'tag':str,'version':str,'ddate':str,'qtrs':'int8','uom':str,'value':str}\n",
    "\n",
    "# Symbols we are interested\n",
    "SYMBOLS = ['GOOG','NVDA','ADBE', 'MSFT','AMZN','TSLA','WMT']\n",
    "\n",
    "# Taxonomies we are considering\n",
    "TAXONOMIES = ['dei', 'us-gaap']\n",
    "\n",
    "# Qtrs we are interested in\n",
    "QTRS_SCOPE = [0, 1, 4]\n",
    "# Regular expression to pass taxonomies\n",
    "TAX_RE = re.compile(f\"({'|'.join(element for element in TAXONOMIES)})/*\")\n",
    "\n",
    "# Batch size\n",
    "BATCH_SIZE = 499\n",
    "\n",
    "# Collection names\n",
    "SUB_COLLECTION = 'sub'\n",
    "NUM_COLLECTION = 'num'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7df60bf-1d95-4f4a-a6a3-c7fc1f5da1db",
   "metadata": {},
   "source": [
    "## Get symbol, cik mapping\n",
    "### Reference: __[Access Companies SEC Filings Using Python](https://medium.datadriveninvestor.com/access-companies-sec-filings-using-python-760e6075d3ad)__\n",
    "### json file used in this method -> https://www.sec.gov/files/company_tickers.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "652d9169-b4ec-4637-83c4-6b3a984065be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_company_tickers() -> pd.DataFrame:\n",
    "    '''\n",
    "    Returns a DataFrame consists of CIK, ticker symbols\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: a DataFrame consists of CIK, ticker symbols or None for any errors\n",
    "    '''\n",
    "    url = 'https://www.sec.gov/files/company_tickers.json'\n",
    "    response = requests.get(url, headers={\n",
    "        'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'\n",
    "    })\n",
    "    df = pd.json_normalize(pd.json_normalize(response.json(), max_level=0).to_numpy()[0])\n",
    "    df.set_index(\"ticker\",inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82cbf7af-bac6-49a2-a9f0-819ffb82a73e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cik_str</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MSFT</th>\n",
       "      <td>789019</td>\n",
       "      <td>MICROSOFT CORP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>320193</td>\n",
       "      <td>Apple Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NVDA</th>\n",
       "      <td>1045810</td>\n",
       "      <td>NVIDIA CORP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <td>1018724</td>\n",
       "      <td>AMAZON COM INC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOGL</th>\n",
       "      <td>1652044</td>\n",
       "      <td>Alphabet Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAYAR</th>\n",
       "      <td>1969475</td>\n",
       "      <td>Bayview Acquisition Corp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QETAR</th>\n",
       "      <td>1978528</td>\n",
       "      <td>Quetta Acquisition Corp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QETAU</th>\n",
       "      <td>1978528</td>\n",
       "      <td>Quetta Acquisition Corp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NETDW</th>\n",
       "      <td>1975218</td>\n",
       "      <td>Nabors Energy Transition Corp. II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NETDU</th>\n",
       "      <td>1975218</td>\n",
       "      <td>Nabors Energy Transition Corp. II</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10423 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        cik_str                              title\n",
       "ticker                                            \n",
       "MSFT     789019                     MICROSOFT CORP\n",
       "AAPL     320193                         Apple Inc.\n",
       "NVDA    1045810                        NVIDIA CORP\n",
       "AMZN    1018724                     AMAZON COM INC\n",
       "GOOGL   1652044                      Alphabet Inc.\n",
       "...         ...                                ...\n",
       "BAYAR   1969475           Bayview Acquisition Corp\n",
       "QETAR   1978528            Quetta Acquisition Corp\n",
       "QETAU   1978528            Quetta Acquisition Corp\n",
       "NETDW   1975218  Nabors Energy Transition Corp. II\n",
       "NETDU   1975218  Nabors Energy Transition Corp. II\n",
       "\n",
       "[10423 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickers_cik = get_company_tickers()\n",
    "tickers_cik"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc09674-5caa-4643-b19e-eb4fff0b56a5",
   "metadata": {},
   "source": [
    "## Maps CIKs to Tickers in SYMBOLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c65df42e-d8d0-4a2f-8416-75097af38247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1652044: 'GOOG',\n",
       " 1045810: 'NVDA',\n",
       " 796343: 'ADBE',\n",
       " 789019: 'MSFT',\n",
       " 1018724: 'AMZN',\n",
       " 1318605: 'TSLA',\n",
       " 104169: 'WMT'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Maps CIK -> ticker\n",
    "cik_ticker_dict = {}\n",
    "for symbol in SYMBOLS:\n",
    "    # Only interested in CIK\n",
    "    cik_ticker_dict[tickers_cik.loc[symbol]['cik_str']] = symbol\n",
    "cik_ticker_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf59739-ee5a-4719-a79a-4dd2205d606e",
   "metadata": {},
   "source": [
    "## Find CIK for Ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1751cf61-f7a2-4702-b58e-66c1b5749441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_cik(ticker:str) -> str:\n",
    "#     '''\n",
    "#     Returns the CIK associate with the stock symbol\n",
    "    \n",
    "#     Parameters:\n",
    "#     ticker (str): the ticker symbol for a stock\n",
    "    \n",
    "#     Returns:\n",
    "#     str: CIK associated with given ticket symbol or None if ticker is not part of the SYMBOLS constant\n",
    "#     '''\n",
    "#     if ((ticker not in SYMBOLS) or (ticker not in tickers_cik.index)):\n",
    "#         return None\n",
    "#     return tickers_cik.loc[ticker]['cik_str']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98323f5f-1192-41fb-bd49-1ddd8b180e53",
   "metadata": {},
   "source": [
    "## Firestore DB access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0ef94fb-9f3c-46bf-b57c-3f2dc44a5b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a service account.\n",
    "cred = credentials.Certificate(f\"{os.path.join(CONFIG_PATH,'keys.json')}\")\n",
    "app = firebase_admin.initialize_app(cred)\n",
    "db = firestore.client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ed85d6-ece5-4522-8ead-724348931c64",
   "metadata": {},
   "source": [
    "## Helper method to batch data\n",
    "### Reference: __[Importing data into Firestore using Python](https://medium.com/@cbrannen/importing-data-into-firestore-using-python-dce2d6d3cd51)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2dad8f85-5347-482d-b90d-b6051266eee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_data(iterable, n=1):\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, n):\n",
    "        yield iterable[ndx:min(ndx + n, l)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78412359-6de6-48a9-83e7-a294e339dfde",
   "metadata": {},
   "source": [
    "## Add a DF to firestore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0899af1f-c0e2-4c44-a4e1-3b770b7a9c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_df(df:pd.DataFrame, name:str):\n",
    "    result = df.to_json(orient='records')\n",
    "    parsed = json.loads(result)\n",
    "    \n",
    "    for idx, batched_data in enumerate(batch_data(parsed, BATCH_SIZE)):\n",
    "        batch = db.batch()\n",
    "        for data_item in batched_data:\n",
    "            doc_ref = db.collection(name).document()\n",
    "            batch.set(doc_ref, data_item)\n",
    "        batch.commit()\n",
    "        print(f'Committed batch - {idx}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87616354-cbae-4fbc-8c01-a550836b8e72",
   "metadata": {},
   "source": [
    "## Load Submissions Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5eff2228-df34-4ca5-bd52-172047042f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_subs(filename:str, ciks:List) -> pd.DataFrame:\n",
    "    # Derive the dataset based on the filename\n",
    "    _,dataset,_ = filename.split(os.path.sep)\n",
    "    try:\n",
    "        # Read data with pandas\n",
    "        df = pd.read_csv(filename, sep='\\t', dtype=SUB_DTYPES, usecols=SUB_DTYPES.keys())\n",
    "    except Exception as error:\n",
    "        print(\"An error occurred:\", error, filename)\n",
    "        # if this fails create an empty pandas dataframe with the same SUB_DTYPES as the good data\n",
    "        df = pd.read_csv(io.StringIO(''), dtype=SUB_DTYPES, usecols=SUB_DTYPES.keys())\n",
    "\n",
    "    # Custom field - adds the dataset name\n",
    "    df['dataset'] = dataset\n",
    "\n",
    "    # Filter out any forms we are not interested for SUB\n",
    "    df = df.query('(form in @FORMS_SCOPE) & (cik in @ciks)')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a1a89b-3d16-486d-8aa5-15a01d947e43",
   "metadata": {},
   "source": [
    "## Create SUB Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e31c63b-4d77-4132-8a71-46254e2cea06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Committed batch - 0\n",
      "Committed batch - 0\n",
      "Committed batch - 0\n",
      "Committed batch - 0\n",
      "Committed batch - 0\n",
      "Committed batch - 0\n",
      "Committed batch - 0\n",
      "Committed batch - 0\n",
      "CPU times: user 1.05 s, sys: 169 ms, total: 1.22 s\n",
      "Wall time: 1.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# List of files we are going to load\n",
    "files = [f for f in Path(DATA_PATH).glob(os.path.join('20*q*', 'sub.*'))]\n",
    "# List of CIKs we are interested\n",
    "ciks = list(cik_ticker_dict.keys())\n",
    "# List of adsh values for SUB\n",
    "adsh_list = []\n",
    "# Loop through files\n",
    "for file in files:\n",
    "    df = read_subs(str(file), ciks)\n",
    "\n",
    "    # Set columns as per SUBs specification\n",
    "    for key in ['period','filed','accepted']:\n",
    "        df[key] = df[key].astype('datetime64[ns]')\n",
    "        \n",
    "    df['sic'] = df['sic'].astype('Int16')\n",
    "    df['fy']= df['fy'].astype('Int16')\n",
    "    # Add adsh of the current df to the list of adsh\n",
    "    [adsh_list.append(x) for x in df['adsh'].to_list()]\n",
    "    add_df(df=df, name=SUB_COLLECTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a66c35d-21fd-4c58-9097-c05963c881bc",
   "metadata": {},
   "source": [
    "## Load NUM Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2407efee-70d6-4d54-83da-ece7aa0da159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_nums(filename:str, sub_adsh:List) -> pd.DataFrame:\n",
    "    # Derive the dataset based on the filename\n",
    "    _,dataset,_ = filename.split(os.path.sep)\n",
    "    try:\n",
    "        # Read data with pandas\n",
    "        df = pd.read_csv(filename, sep='\\t', dtype=NUM_DTYPES, usecols=NUM_DTYPES.keys())\n",
    "    except Exception as error:\n",
    "        print(\"An error occurred:\", error, filename)\n",
    "        # if this fails create an empty pandas dataframe with the same NUM_DTYPES as the good data\n",
    "        df = pd.read_csv(io.StringIO(''), dtype=NUM_DTYPES, usecols=NUM_DTYPES.keys())\n",
    "\n",
    "    # Custom field - adds the dataset name\n",
    "    df['dataset'] = dataset\n",
    "    # Columns contains True if the record contains taxonomies in scope\n",
    "    df['taxonomies'] = df['version'].apply(lambda x: TAX_RE.match(x) != None)\n",
    "    # Filter out quarters, include adsh beloging to subs and records with taxonomies in scope\n",
    "    df = df.query('(qtrs in @QTRS_SCOPE) & (adsh in @sub_adsh) & (taxonomies)')\n",
    "    # Drop this column as we don't need it anymore\n",
    "    df = df.drop(columns=['taxonomies'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016c62b1-4c51-473f-9c8c-cc1c00905479",
   "metadata": {},
   "source": [
    "## Create NUM Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "114a4946-baaa-4858-973d-2685243f3be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Committed batch - 0\n",
      "Committed batch - 1\n",
      "Committed batch - 2\n",
      "Committed batch - 3\n",
      "Committed batch - 4\n",
      "Committed batch - 0\n",
      "Committed batch - 1\n",
      "Committed batch - 2\n",
      "Committed batch - 3\n",
      "Committed batch - 4\n",
      "Committed batch - 5\n",
      "Committed batch - 6\n",
      "Committed batch - 7\n",
      "Committed batch - 0\n",
      "Committed batch - 1\n",
      "Committed batch - 2\n",
      "Committed batch - 3\n",
      "Committed batch - 4\n",
      "Committed batch - 0\n",
      "Committed batch - 1\n",
      "Committed batch - 2\n",
      "Committed batch - 3\n",
      "CPU times: user 18.6 s, sys: 1.65 s, total: 20.2 s\n",
      "Wall time: 38.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# List of files we are going to load\n",
    "# 2022, 2023 done\n",
    "files = [f for f in Path(DATA_PATH).glob(os.path.join('2022q*', 'num.*'))]\n",
    "# Loop through files\n",
    "for file in files:\n",
    "    df = read_nums(str(file), adsh_list)\n",
    "    # Convert value to float\n",
    "    df['value'] = df['value'].astype(float)\n",
    "    # Convert to date time format\n",
    "    df['ddate'] = df['ddate'].astype('datetime64[ns]')\n",
    "    add_df(df=df, name=NUM_COLLECTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c18a40b-4002-4c4b-a51f-26ea745263dd",
   "metadata": {},
   "source": [
    "## Find out the collection size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6584c572-bff1-4be4-97a6-7cb0ff2339e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collection_size(name:str) -> List:\n",
    "    # Count all docs in collection\n",
    "    collection = db.collection(name)\n",
    "    count_query = collection.count()\n",
    "    return count_query.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19f996a8-6f5f-44e6-8458-69229ba6a281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of docs in sub collection: 56\n",
      "No of docs in num collection: 20036\n"
     ]
    }
   ],
   "source": [
    "res = collection_size(name=SUB_COLLECTION)\n",
    "print(f'No of docs in {SUB_COLLECTION} collection: {res[0][0].value}')\n",
    "res = collection_size(name=NUM_COLLECTION)\n",
    "print(f'No of docs in {NUM_COLLECTION} collection: {res[0][0].value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c70f39c-043d-4366-961b-f4d494064d6b",
   "metadata": {},
   "source": [
    "## Helper method to delete a collection\n",
    "### Reference: __[Delete data from Cloud Firestore](https://firebase.google.com/docs/firestore/manage-data/delete-data)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c56330b-8296-4b92-8524-7277f3f89dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_collection(coll_ref, batch_size):\n",
    "    if batch_size == 0:\n",
    "        return\n",
    "\n",
    "    docs = coll_ref.list_documents(page_size=batch_size)\n",
    "    deleted = 0\n",
    "\n",
    "    for doc in docs:\n",
    "        # print(f\"Deleting doc {doc.id} => {doc.get().to_dict()}\")\n",
    "        doc.delete()\n",
    "        deleted = deleted + 1\n",
    "\n",
    "    if deleted >= batch_size:\n",
    "        return delete_collection(coll_ref, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a830c361-a5ec-4d27-b312-3a381131f924",
   "metadata": {},
   "source": [
    "## Delete collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8fb25780-c5c0-4723-87dd-0a84f11207ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete_collection(db.collection(SUB_COLLECTION), BATCH_SIZE)\n",
    "# delete_collection(db.collection(NUM_COLLECTION), BATCH_SIZE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
